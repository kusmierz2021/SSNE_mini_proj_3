{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_all_seeds(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def check_classes_amount(set_with_labels):\n",
    "    counter = [1,0,0,0,0,0,0,0,0,0,\n",
    "               0,0,0,0,0,0,0,0,0,0,\n",
    "               0,0,0,0,0,0,0,0,0,0,\n",
    "               0,0,0,0,0,0,0,0,0,0,\n",
    "               0,0,0,0,0,0,0,0,0,0]\n",
    "    count = 0\n",
    "    for j in tqdm(range(88010)):\n",
    "        if set_with_labels[j][1] == set_with_labels[j+1][1]:\n",
    "            counter[count] = counter[count] + 1\n",
    "        else:\n",
    "            count += 1\n",
    "            counter[count] = counter[count] + 1\n",
    "\n",
    "    return counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def over_sample_bread_carbon():\n",
    "    classes_amounts = check_classes_amount(trainset)\n",
    "    sub_folders = os.listdir(\"./train\")\n",
    "    list_of_images_bread = os.listdir(f\"./train/{sub_folders[10]}\")\n",
    "    list_of_images_carbon = os.listdir(f\"./train/{sub_folders[13]}\")\n",
    "\n",
    "    to_oversample_bread = random.sample(list_of_images_bread, k=(1800 - classes_amounts[10]))\n",
    "    to_oversample_carbon = random.sample(list_of_images_carbon, k= (1800 - 3 * classes_amounts[13]))\n",
    "\n",
    "    # oversample bread class\n",
    "    for i in range(len(to_oversample_bread)):\n",
    "        shutil.copy(f\"./train/{sub_folders[10]}/{to_oversample_bread[i]}\", f\"./train/{sub_folders[10]}/{[name[:-5] + '_1' + name[-5:] for name in to_oversample_bread][i]}\")\n",
    "\n",
    "    # oversample carbon class\n",
    "    for i in range(classes_amounts[13]):\n",
    "        shutil.copy(f\"./train/{sub_folders[13]}/{list_of_images_carbon[i]}\", f\"./train/{sub_folders[13]}/{[name[:-5] + '_1' + name[-5:] for name in list_of_images_carbon][i]}\")\n",
    "\n",
    "    for i in range(classes_amounts[13]):\n",
    "        shutil.copy(f\"./train/{sub_folders[13]}/{list_of_images_carbon[i]}\", f\"./train/{sub_folders[13]}/{[name[:-5] + '_2' + name[-5:] for name in list_of_images_carbon][i]}\")\n",
    "\n",
    "    for i in range(len(to_oversample_carbon)):\n",
    "        shutil.copy(f\"./train/{sub_folders[13]}/{to_oversample_carbon[i]}\", f\"./train/{sub_folders[13]}/{[name[:-5] + '_3' + name[-5:] for name in to_oversample_carbon][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainset = datasets.ImageFolder(\"train/\")\n",
    "# over_sample_bread_carbon()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create val folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_val_folder():\n",
    "    sub_folders = os.listdir(\"./train\")\n",
    "    os.mkdir(\"./val\")\n",
    "    for sub_folder in sub_folders:\n",
    "        os.mkdir(f\"./val/{sub_folder}\")\n",
    "\n",
    "    for sub_folder in sub_folders:\n",
    "        to_move = random.sample(os.listdir(f\"./train/{sub_folder}\"), k=360)\n",
    "        for image in to_move:\n",
    "            shutil.move(f\"./train/{sub_folder}/{image}\", f\"./val/{sub_folder}/{image}\")\n",
    "\n",
    "# create_val_folder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(0.5),\n",
    "     transforms.RandomVerticalFlip(0.5),\n",
    "     transforms.RandomRotation(24),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.RandomErasing(0.4),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainset = datasets.ImageFolder(\"train/\", transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "valset = datasets.ImageFolder(\"val/\", transform=transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testset = datasets.ImageFolder(\"test_all/\", transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "classes = tuple(trainset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images).cpu()\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "    return 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Net preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Net(\n  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(64, 150, kernel_size=(3, 3), stride=(1, 1))\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv3): Conv2d(150, 150, kernel_size=(3, 3), stride=(1, 1))\n  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (drop): Dropout(p=0.2, inplace=False)\n  (conv4): Conv2d(150, 150, kernel_size=(3, 3), stride=(1, 1))\n  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc0): Linear(in_features=600, out_features=300, bias=True)\n  (fc3): Linear(in_features=300, out_features=150, bias=True)\n  (fc4): Linear(in_features=150, out_features=50, bias=True)\n)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "##Warstwakonwolucyjna\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=64,kernel_size=3,stride=1,padding=0)\n",
    "##Warstwamaxpooling\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2 = nn.Conv2d(64,150,3)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(150, 150, 3)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.conv4 = nn.Conv2d(150, 150, 3)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.fc0 = nn.Linear(600,300)\n",
    "        # self.fc1 = nn.Linear(2200,1100)\n",
    "        # self.fc2 = nn.Linear(1100,500)\n",
    "        self.fc3 = nn.Linear(300, 150)\n",
    "        self.fc4 = nn.Linear(150,50)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = self.drop(x)\n",
    "        x = self.pool4(F.relu(self.conv4(x)))\n",
    "        x = torch.flatten(x,1)#flattenalldimensionsexceptbatch\n",
    "        x = F.relu(self.fc0(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1125it [01:39, 11.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/8] loss: 1.579\n",
      "accuracy on trainloader: 56.727777777777774\n",
      "accuracy on valloader: 46.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1125it [03:20,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/8] loss: 1.557\n",
      "accuracy on trainloader: 57.43194444444445\n",
      "accuracy on valloader: 46.49444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1125it [02:34,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/8] loss: 1.528\n",
      "accuracy on trainloader: 57.606944444444444\n",
      "accuracy on valloader: 46.388888888888886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1125it [02:01,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/8] loss: 1.510\n",
      "accuracy on trainloader: 59.09027777777778\n",
      "accuracy on valloader: 46.44444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1125it [01:49, 10.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/8] loss: 1.487\n",
      "accuracy on trainloader: 58.455555555555556\n",
      "accuracy on valloader: 46.71666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1125it [01:45, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/8] loss: 1.473\n",
      "accuracy on trainloader: 59.325\n",
      "accuracy on valloader: 46.44444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1125it [01:44, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/8] loss: 1.449\n",
      "accuracy on trainloader: 59.50555555555555\n",
      "accuracy on valloader: 46.272222222222226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1125it [01:43, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/8] loss: 1.435\n",
      "accuracy on trainloader: 59.74444444444445\n",
      "accuracy on valloader: 46.516666666666666\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 8\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(trainloader, 0)):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('[%d/%d] loss: %.3f' %\n",
    "          (epoch+1, epochs,  running_loss / len(trainloader)))\n",
    "    running_loss = 0.0\n",
    "\n",
    "\n",
    "    print(f\"accuracy on trainloader: {get_accuracy(trainloader)}\")\n",
    "    print(f\"accuracy on valloader: {get_accuracy(valloader)}\")\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "outputs = net(images.to(device))\n",
    "#outputs\n",
    "print(len(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  elephant motor bacteria spice tomato   egg towel antenna spoon birch   tea acoustic monkey hammer flower kangaroo tomato acoustic  crab  frog bacteria  frog camera camera camera beetle  fish snake turtle   saw icecream motor fungus turtle truck   cat motor printer   tea hammer crocodilian monkey squash pizza echinoderm   cat bread   cat bridge elephant  corn  palm squash   tea spice beetle bicycle spider fungus swine  corn  bird fungus   cat\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(len(predicted))))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Making predictions to .csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images).cpu()\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # print(predicted)\n",
    "        for i in predicted:\n",
    "            predictions.append(i.item())\n",
    "\n",
    "# print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "#     100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0\n",
      "0  47\n",
      "1  31\n",
      "2   2\n",
      "3  14\n",
      "4  45\n"
     ]
    }
   ],
   "source": [
    "list_of_test_img = os.listdir(f\"./test_all/test_all\")\n",
    "img_name = pd.DataFrame(list_of_test_img)\n",
    "# print(list_of_test_img)\n",
    "pred = pd.DataFrame(predictions)\n",
    "print(pred.head())\n",
    "results = pd.concat([img_name, pred], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(img_name[0].unique()))\n",
    "print(len(pred[0].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "results.to_csv('Kusmierz_Podolec_48.csv', header=None, index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}